
## Links:
- Markdown guide: https://paperhive.org/help/markdown
- OpenAPI: http://127.0.0.1:8000/docs
- github: https://github.com/kenlong2206/calculator
- sonarcloud: https://sonarcloud.io/project/branches_list?id=kenlong2206_calculator
- dockerhub: https://hub.docker.com/repository/docker/kenlongdocker/calculator-app/general
___

## Directory Structure
- all code in `src` directory
- all tests in `tests` directory. Unit tests in `unit`. Other directories to be created as more testing is added 
- all test results in `tests/test_reports`
- list of packages to be installed in `requirements.txt`
- a number of config and ini files in root e.g. `.coverage, .dockerignore, .gitignore, Dockerfile, etc`
- ignore `venv` (virtual environment) and `.pytest_cache` files (autogenerated and should not be in git)
___

## Python Virtual Environment
- venv is a module in Python that provides support for creating lightweight "virtual environments" with their own site directories, optionally isolated from system site directories. Each virtual environment has its own Python binary (which matches the version of the binary that was used to create this environment) and can have its own independent set of installed Python packages.
- When you create a virtual environment, it creates a directory structure that contains a copy of the Python interpreter and standard library. This structure is isolated from the global Python installation. Any packages installed in the virtual environment using pip are installed only in that environment and are not available to the global Python installation or other virtual 
- To create a venv: `python -m venv venv`. This command creates a directory named venv with a series of directories and files to manage the virtual environment
- To activate a venv: `.\venv\Scripts\activate`
- to deactivate `deavtivate`
- when active, the terminal shows `(venv)` at the start of each command line: e.g. `(venv) PS C:\Users\kenlo\PycharmProjects\calculator>`
- If the `(venv)` is not shown then not in a virtual environment
___

## GIT Setup
- `/.gitignore` file to tell git to ignore certain file types and not add them to git
- gitflow branching model
- setup authentication between local git anf github (use PAT)

___
## Code
- all calculator code in `src/main.py`. a single class with 2 endpoints (`/` and `/calculate`)
- class setup to allow 2 floats and a string (operation) to be passed to the `calculate` end point
- built using `fastAPI` framework with `pedantic` for data validation
- use `uvicorn` as an ASGI server (Asynchronous Server Gateway Interface) to serve the application. It handles asynchronous I/O, HTTP/2 websocket support
- to run from command line: `uvicorn src.main:app --reload` (reload will automatically restart server when changes are made)
- openAPI visible on `http://127.0.0.1:8000/docs`
- to run curl from command line:
  - ```curl -Method POST -Uri http://127.0.0.1:8000/calculate -Headers @{'accept'='application/json'; 'Content-Type'='application/json'} -Body '{"num1": 5, "num2": 12, "operation": "multiply"}'```

___
## Logging
- logging setup code in `src/logging_setup.py`
- logs written to `calculator/logs`
   - to write to logs use logger.info, .warn, .debug, .error, etc. e.g. `logger.info("Add operation")`

___
## Unit Testing
- unit test files start with `test_<name of module being tested>` (pytest will search for these files)
- unit tests for `main.py` in '/tests/unit/test_main.py'
- unit tests use pytest (need pip install pytest)
- coverage report uses `pytest-cov` (need pip install pytest-cov)
- each test posts a json string to the endpoint, and uses assert statements to check a valid response (status code 200) is received, and the result returned is correct)
- pytest config stored in `.pytest.ini`
  - the following options are set: ```- --cov=src --cov-report=xml:tests/test_reports/coverage.xml --cov-report=html:tests/test_reports/htmlcov --junitxml=tests/test_reports/xunit-result.xml```. This runs the coverage addin and stores results in `tests/test_reports` 
- tests can be run from the command line from project root directory (`...Pycharm Projects/calculator`): ` python -m pytest` 
- a run configuration can also be setup to run from within pycharm

___
## CI Pipeline
- github workflow automation files in `.github/workflows`
- ci workflow in `ci.yml`

___
## SonarCloud
- sonar properties stored in project root `sonar-project.properties`
- login at `https://sonarcloud.io/` (select login via Github)
- on top menu bar click `Account -> My Organisations`. Click to create an account if needed
- on top menu bar click `+` -> `Analyse New Project`. it should list all the github projects. select the one to be analysed
  - click `My Projects` and click the project
  - on left nav under `Information` copy the `Project Key` and `Organisation Key` and paste them into the ci.yml file in the approprate sonar properties
- paste them into `sonar-project.properties`:
  ```  
    sonar.projectKey=<project key>
    sonar.organization=<organisation key>
  ```
- setup a secure connection between sonar and github 
  - on top menu bar click `Account -> My Organisations`
    - select `Security` tab
      - enter a token name e.g. calculator and click `generate`
    - copy the resulting secret
    - goto `github`, select the 'calculator' project and click `Settings -> Secrets and Variables -> Actions`
    - click `New Repository Secret`
    - enter `SONAR_TOKEN` and paste in the secret. click `Add Secret`. Notice `SONAR_TOKEN` is referenced in `ci.yml` 
  > NOTE: There are sonar properties in the workflow yml file and `sonar-project.properties`. Used trial and error to figure out which ones belong where - could do with tidying up sometime 

  > NOTE: SonarCloud would not pickup coverage reports so workaround was to add a `.coveragerc` file in project root
 
___
## Integration Tests - Postman
- To use postman and integrate into the pipeline:
  - create a postman collection containing API requests and tests
  - export the postman collection and environment as JSON files
  - use 'Newman' to run postman tests (Newman is a command-line collection runner for Postman allowing postman tests to be run from the command line)
  - Integrate Newman into the CI pipeline
- To create a postman collection:
  - Click to create new collection
  - in main section enter URL endpoint and select method: GET, POST, etc
  - In headers, ensure 'Content-type' is 'application/json'
  - In `Body -> Raw` enter the JSON string to be posted
  - In `Scripts -> Post-res` enter the tests:
    - To check the return status:
      ```
      pm.test("Returns 200 OK status", () => {
      pm.response.to.have.status(200)
      });
      ```
    - To check the response time:
      ```
      pm.test("Response time is less than 500ms", function () {
      pm.expect(pm.response.responseTime).to.be.below(500);
      });
      ```
    - To check the content type:
      ```
      pm.test("Content-Type is application/json", function () {
      pm.response.to.have.header("Content-Type", "application/json");
      });    
      ```
    - To check the returned result:
      ```
      pm.test("Response body contains the correct result", function () {
      var jsonData = pm.response.json();
      pm.expect(jsonData).to.have.property('result', 3);
      });    
      ```
    - To check the returned message:
      ```
      pm.test("Response body contains the correct result", function () {
      var jsonData = pm.response.json();
      pm.expect(jsonData).to.have.property('detail', 'Division by zero is not allowed');
      });    
      ```
- Export the postman collection json to directory `tests/integration/`
- install newman: `npm install -g newman`



___
## Docker 
- install docker desktop so the docker CLI is installed
- check it works by typing `docker` from terminal/cmd
- to connect the decktop to dockerhub, login to dockerhub `https://hub.docker.com/` and select `user -> My Account -> Security`
- click `New Access Token`, name it and copy the secret
- back to desktop type `docker login -u <dockerhub username>` and paste in secret for password.
- Create a docker image and tag it
```
docker build -t calculator-app . 
docker tag calculator-app kenlongdocker/calculator-app:latest
```
- Push the image to dockerhub image repository
```
docker push kenlongdocker/calculator-app:latest
```
- pull the latest image from the repository
```
docker pull kenlongdocker/calculator-app:latest
```
- run the image (a running instance of a docker image is a docker container)
```
docker run -d -p 8000:8000 kenlongdocker/calculator-app:latest 
```
- to view running docker containers
```
docker ps
```
- to kill a docker container
```
docker kill <container id>
```
- to run the docker container interactively
```
docker run -it calculator-app /bin/sh
```
- to view docker logs
```
docker logs kenlongdocker/calculator-app:latest
```
## Docker Compose
- included with Docker Desktop



## JFrog Artifactory
- login with github credentials

## Selenium

## Pact

## Blazemeter

## Infrastructure as Code
